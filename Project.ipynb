{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Project.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "4GS0yuGl0mHQ"
      },
      "source": [
        "import torch\n",
        "print('Version', torch.__version__)\n",
        "print('CUDA enabled:', torch.cuda.is_available())\n",
        "  \n",
        "# Running this should then print out:\n",
        "# Version 1.7.0+cu101 (or something like this)\n",
        "# CUDA enabled: True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6t3ZIEll0pr-"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "!ls /gdrive"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CLVJPc_90vsB"
      },
      "source": [
        "import os\n",
        "BASE_PATH = '/gdrive/My Drive/colab_files/'\n",
        "DATA_PATH = '/gdrive/My Drive/colab_files/mel_spec_dataset_amplified/'\n",
        "\n",
        "#UNCOMMENT FOLLOWING SECTION TO UNTAR DATASETS\n",
        "#MODIFY FILE NAMES AS NEEDED\n",
        "'''\n",
        "if not os.path.exists(DATA_PATH):\n",
        "    os.makedirs(DATA_PATH)\n",
        "print(os.getcwd())\n",
        "\n",
        "os.chdir(BASE_PATH)\n",
        "!ls\n",
        "!tar -zxf mel_spec_data_amplified.tar.gz mel_spec_dataset_amplified/test_combined \n",
        "print('Extracted test set')\n",
        "!tar -zxf mel_spec_data_amplified.tar.gz mel_spec_dataset_amplified/train_combined\n",
        "print('Extracted train set')\n",
        "!tar -zxf mel_spec_data_amplified.tar.gz mel_spec_dataset_amplified/train_data_ms_list.csv\n",
        "!tar -zxf mel_spec_data_amplified.tar.gz mel_spec_dataset_amplified/test_data_ms_list.csv\n",
        "print('Extracted data lists')\n",
        "!cp \"pt_util.py\" \"/gdrive/My Drive/colab_files/mel_spec_dataset_amplified/\"\n",
        "print('Copied pt_util')\n",
        "#!ls -1 | wc -l\n",
        "'''\n",
        "os.chdir(DATA_PATH)\n",
        "!ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F1N6-Nm2nka5"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import csv\n",
        "import sys\n",
        "import pickle\n",
        "import re\n",
        "import pt_util\n",
        "\n",
        "!ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w5rTmJKRlfIo"
      },
      "source": [
        "def create_dict():\n",
        "    dict = {}\n",
        "    with open('train_data_ms_list.csv') as csv_file:\n",
        "        csv_reader = csv.reader(csv_file, delimiter=',')\n",
        "        count = 0\n",
        "        for row in csv_reader:\n",
        "            if row[1] not in dict:\n",
        "                dict[row[1]] = count\n",
        "                count = count + 1\n",
        "    return dict"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jOeWIWje3xhJ"
      },
      "source": [
        "#COMBINED\n",
        "class FreesoundDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, data_file, dictionary, num_mset, dir):\n",
        "        super(FreesoundDataset, self).__init__()\n",
        "        self.data = []\n",
        "        self.labels = []\n",
        "        self.dict = dictionary\n",
        "        row_count = 0\n",
        "        with open(data_file) as csv_file:\n",
        "            csv_reader = csv.reader(csv_file, delimiter=',')\n",
        "            for row in csv_reader:\n",
        "                self.labels.append(row[1])\n",
        "\n",
        "        for i in range(num_mset):\n",
        "            name = dir + 'MSet' + str(i) + '.npy'\n",
        "            data_np = np.load(name)\n",
        "            for sample in data_np:\n",
        "                self.data.append(sample)\n",
        "            print('read ' + name)\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        data_array = self.data[idx]\n",
        "        data_image = np.stack([data_array]*3)\n",
        "        data_image = data_image.astype('float32')\n",
        "        label_num = self.dict[self.labels[idx]]\n",
        "        return data_image, label_num\n",
        "\n",
        "    def num_classes(self):\n",
        "        return len(self.dict)   \n",
        "\n",
        "\n",
        "dictionary = create_dict()\n",
        "print(dictionary)\n",
        "#COMBINED\n",
        "print('Loading test data set...')\n",
        "#CHANGE NUM TO 19 FOR TEST PADDED, 16 FOR UNPADDED\n",
        "data_test = FreesoundDataset('test_data_ms_list.csv', dictionary, 16, 'test_combined/') \n",
        "print('Length of test dataset:' + str(len(data_test)))\n",
        "\n",
        "print('Loading train data set...')\n",
        "#CHANGE NUM TO 123 FOR COMPLETE SET, 156 FOR AMPLIFIED, 37 FOR VERIFIED\n",
        "data_train = FreesoundDataset('train_data_ms_list.csv', dictionary, 156, 'train_combined/')\n",
        "print('Length of train data set:' + str(len(data_train)))\n",
        "print('Number of classes:' + str(data_train.num_classes()))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "amTH0UULyPTC"
      },
      "source": [
        "#TO DISPLAY MEL SPECTOGRAMS\n",
        "from matplotlib import pyplot as plt\n",
        "for i in range (10):\n",
        "  data, label = data_test.__getitem__(i)\n",
        "  data1 = np.transpose(data[0])\n",
        "  plt.imshow(data1 , interpolation='nearest')\n",
        "  plt.gray()\n",
        "  plt.gca().invert_yaxis()\n",
        "  plt.xlabel('Time')\n",
        "  plt.ylabel('Mel bins')\n",
        "  plt.show()\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tykNFscmuxrd"
      },
      "source": [
        "#preparing pretrained network\n",
        "import torchvision.models as models\n",
        "from torchsummary import summary\n",
        "def get_vgg_model():\n",
        "  model = models.vgg11(pretrained = True)\n",
        "  model.features = nn.Sequential(*[model.features[i] for i in range(16)])\n",
        "  model.avgpool = nn.Identity()\n",
        "  model.classifier[0] =  nn.Linear(12288, 4096)\n",
        "  model.classifier[6] = nn.Linear(4096, 41)\n",
        "  \n",
        "  #freezing weights from all layers\n",
        "  for param in model.parameters(): # freeze\n",
        "    param.requires_grad = False\n",
        "  \n",
        "  #unfreezing weight for classifier layers\n",
        "  for i in range(7):\n",
        "    for param in model.classifier[i].parameters(): # train the last linear layer.\n",
        "      param.requires_grad = True\n",
        "  model = model.cuda()\n",
        "  #print(model)\n",
        "  summary(model, (3, 96, 64))\n",
        "  return model\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OoHceNvURy7e"
      },
      "source": [
        "import torchvision.models as models\r\n",
        "def get_resnet_model():\r\n",
        "  model_r = models.resnet18(pretrained = True)\r\n",
        "  model_r.layer4 = nn.Identity()\r\n",
        "  model_r.avgpool = nn.Identity()\r\n",
        "  model_r.fc = nn.Linear(6144, 41)\r\n",
        "  \r\n",
        "  for param in model_r.parameters():\r\n",
        "      param.requires_grad = False\r\n",
        "      \r\n",
        "  for param in model_r.fc.parameters():\r\n",
        "    param.requires_grad = True\r\n",
        "    \r\n",
        "  model_r = model_r.cuda()\r\n",
        "  summary(model_r, (3, 96, 64))\r\n",
        "  return model_r"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z7ydxhlXIjeL"
      },
      "source": [
        "def save_model(model, file_path, num_to_keep=1):\n",
        "    pt_util.save(model, file_path, num_to_keep)\n",
        "\n",
        "def load_model(model, file_path):\n",
        "    print('loading model')\n",
        "    pt_util.restore(model, file_path)\n",
        "\n",
        "def load_last_model(model, dir_path):\n",
        "    print('loading last model')\n",
        "    return pt_util.restore_latest(model, dir_path)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "__ZtvF47JnEw"
      },
      "source": [
        "import time\n",
        "def train(model, device, train_loader, optimizer, epoch, log_interval):\n",
        "    model.train()\n",
        "    losses = []\n",
        "    criterion = F.cross_entropy\n",
        "    for batch_idx, (data, label) in enumerate(train_loader):\n",
        "        data, label = data.to(device), label.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = criterion(output, label, reduction='mean')\n",
        "        losses.append(loss.item())\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if batch_idx % log_interval == 0:\n",
        "            print('{} Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                time.ctime(time.time()),\n",
        "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "                100. * batch_idx / len(train_loader), loss.item()))\n",
        "    return np.mean(losses)\n",
        "\n",
        "def test(model, device, test_loader, log_interval=None, traindata = False):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    criterion = F.cross_entropy\n",
        "    if traindata:\n",
        "      name = 'Train'\n",
        "    else:\n",
        "      name = 'Test'\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (data, label) in enumerate(test_loader):\n",
        "            data, label = data.to(device), label.to(device)\n",
        "            output = model(data)\n",
        "            test_loss_on = criterion(output, label, reduction='sum').item()\n",
        "            test_loss += test_loss_on\n",
        "            pred = output.max(1)[1]\n",
        "            correct_mask = pred.eq(label.view_as(pred))\n",
        "            num_correct = correct_mask.sum().item()\n",
        "            correct += num_correct\n",
        "            \n",
        "            if log_interval is not None and batch_idx % log_interval == 0:\n",
        "                print('{} Data: [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                    time.ctime(time.time()),\n",
        "                    batch_idx * len(data), len(test_loader.dataset),\n",
        "                    100. * batch_idx / len(test_loader), test_loss_on))\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    test_accuracy = 100. * correct / len(test_loader.dataset)\n",
        "\n",
        "    print('\\n' + name + ' set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "        test_loss, correct, len(test_loader.dataset), test_accuracy))\n",
        "    \n",
        "    return test_loss, test_accuracy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Jd_asDR5o07"
      },
      "source": [
        "BATCH_SIZE = 128\n",
        "TEST_BATCH_SIZE = 10\n",
        "EPOCHS = 10\n",
        "LEARNING_RATE = 0.01\n",
        "MOMENTUM = 0.9\n",
        "USE_CUDA = True\n",
        "SEED = 0\n",
        "PRINT_INTERVAL = 50\n",
        "WEIGHT_DECAY = 0\n",
        "\n",
        "VERSION = \"7.18\" # increment this to start a new experiment\n",
        "LOG_PATH = DATA_PATH + 'logs/' + VERSION + '/'\n",
        "\n",
        "use_cuda = USE_CUDA and torch.cuda.is_available()\n",
        "\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "print('Using device', device)\n",
        "import multiprocessing\n",
        "print('num cpus:', multiprocessing.cpu_count())\n",
        "\n",
        "kwargs = {'num_workers': multiprocessing.cpu_count(),\n",
        "          'pin_memory': True} if use_cuda else {}\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(data_train, batch_size=BATCH_SIZE,\n",
        "                                           shuffle=True, **kwargs)\n",
        "test_loader = torch.utils.data.DataLoader(data_test, batch_size=TEST_BATCH_SIZE,\n",
        "                                          shuffle=False, **kwargs)\n",
        "print('Loaded data')\n",
        "#CHANGE TO TRY RESNET OR VGG\n",
        "#model = get_vgg_model()\n",
        "model = get_resnet_model()\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr=LEARNING_RATE, momentum=MOMENTUM, weight_decay=WEIGHT_DECAY)\n",
        "start_epoch = load_last_model(model, LOG_PATH)\n",
        "\n",
        "train_accuracies, train_losses, test_losses, test_accuracies = pt_util.read_log(LOG_PATH + 'log.pkl', ([], [], [], []))\n",
        "test_loss, test_accuracy = test(model, device, test_loader)\n",
        "\n",
        "test_losses.append((start_epoch, test_loss))\n",
        "test_accuracies.append((start_epoch, test_accuracy))\n",
        "best_accuracy = None\n",
        "lr = LEARNING_RATE\n",
        "try:\n",
        "    for epoch in range(start_epoch, EPOCHS + 1):\n",
        "        #lr = LEARNING_RATE * np.power(0.25, (int(epoch / 6)))\n",
        "        optimizer = optim.SGD(model.parameters(), lr, momentum=MOMENTUM, weight_decay=WEIGHT_DECAY)\n",
        "        train_loss = train(model, device, train_loader, optimizer, epoch, PRINT_INTERVAL)\n",
        "        __, train_accuracy = test(model, device, train_loader, log_interval=300, traindata=True)\n",
        "        test_loss, test_accuracy = test(model, device, test_loader, log_interval=100)\n",
        "        train_accuracies.append((epoch, train_accuracy))\n",
        "        train_losses.append((epoch, train_loss))\n",
        "        test_losses.append((epoch, test_loss))\n",
        "        test_accuracies.append((epoch, test_accuracy))\n",
        "        pt_util.write_log(LOG_PATH + '.pkl', (train_accuracies, train_losses, test_losses, test_accuracies))\n",
        "        if best_accuracy == None or test_accuracy > best_accuracy:\n",
        "            best_accuracy = test_accuracy\n",
        "            save_model(model, LOG_PATH + '%03d.pt' % epoch)\n",
        "\n",
        "    for param in model.parameters(): # unfreeze\n",
        "      param.requires_grad = True    \n",
        "    tuning_epochs = 15\n",
        "    \n",
        "    \n",
        "    for epoch in range(tuning_epochs):\n",
        "        #lr = LEARNING_RATE * np.power(0.25, (int((EPOCHS + 1 + epoch) / 6)))\n",
        "        lr = LEARNING_RATE * np.power(0.25, (int((epoch) / 6)))\n",
        "        optimizer = optim.SGD(model.parameters(), lr, momentum=MOMENTUM, weight_decay=0.0005)\n",
        "        train_loss = train(model, device, train_loader, optimizer, EPOCHS + 1 + epoch, PRINT_INTERVAL)\n",
        "\n",
        "        __ , train_accuracy = test(model, device, train_loader, log_interval=300, traindata=True)\n",
        "        test_loss, test_accuracy = test(model, device, test_loader, log_interval=100)\n",
        "        \n",
        "        train_accuracies.append((EPOCHS + 1 + epoch, train_accuracy))\n",
        "        train_losses.append((EPOCHS + 1 + epoch, train_loss))\n",
        "        test_losses.append((EPOCHS + 1 + epoch, test_loss))\n",
        "        test_accuracies.append((EPOCHS + 1 + epoch, test_accuracy))\n",
        "        pt_util.write_log(LOG_PATH + '.pkl', (train_accuracies, train_losses, test_losses, test_accuracies))\n",
        "        if best_accuracy == None or test_accuracy > best_accuracy:\n",
        "            best_accuracy = test_accuracy\n",
        "            save_model(model, LOG_PATH + '%03d.pt' % (epoch + EPOCHS + 1) ) \n",
        "       \n",
        "    \n",
        "except KeyboardInterrupt as ke:\n",
        "    print('Interrupted')\n",
        "except:\n",
        "    import traceback\n",
        "    traceback.print_exc()\n",
        "finally:\n",
        "    save_model(model, LOG_PATH + '%03d.pt' % (epoch + EPOCHS + 1), 0)\n",
        "    ep, val = zip(*train_accuracies)\n",
        "    pt_util.plot(ep, val, 'Train Accuracy', 'Epoch', 'Accuracy')\n",
        "    ep, val = zip(*train_losses)\n",
        "    pt_util.plot(ep, val, 'Train loss', 'Epoch', 'Error')\n",
        "    ep, val = zip(*test_losses)\n",
        "    pt_util.plot(ep, val, 'Test loss', 'Epoch', 'Error')\n",
        "    ep, val = zip(*test_accuracies)\n",
        "    pt_util.plot(ep, val, 'Test accuracy', 'Epoch', 'Accuracy')\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IJxNNutHbELb"
      },
      "source": [
        "def print_metrics(model, data_loader, num_classes): \n",
        "\n",
        "    target_positive = np.zeros(num_classes)\n",
        "    predicted_positive = np.zeros(num_classes)\n",
        "    true_positive = np.zeros(num_classes)\n",
        "    true_negative = np.zeros(num_classes)\n",
        "    precision = np.zeros(num_classes)\n",
        "    recall = np.zeros(num_classes)\n",
        "    f1score = np.zeros(num_classes)\n",
        "    perclass_acc = np.zeros(num_classes)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for j, (inputs, classes) in enumerate(data_loader):\n",
        "            inputs = inputs.to(device)\n",
        "            classes = classes.to(device)\n",
        "            outputs = model(inputs)\n",
        "            #UNCOMMENT THIS FOR NONE CLASS TESTING\n",
        "            '''\n",
        "            all_predicted_probs = F.softmax(outputs, dim=1)\n",
        "            predicted = torch.max(all_predicted_probs, 1)\n",
        "            pred_probs = predicted[0]\n",
        "            pred_classes = predicted[1]\n",
        "            for i in range(len(pred_probs)):\n",
        "                if pred_probs[i] < 0.5:\n",
        "                    pred_classes[i] = 41\n",
        "            '''\n",
        "            for i in range(42):\n",
        "                #predicted_classes = pred_classes == i\n",
        "                predicted_classes = torch.argmax(outputs, dim=1) == i\n",
        "                target_positive[i] += torch.sum(classes == i).float()\n",
        "                predicted_positive[i] += torch.sum(predicted_classes).float()\n",
        "                for k in range(len(predicted_classes)):\n",
        "                    if classes[k] == i and predicted_classes[k]:\n",
        "                        true_positive[i] += 1\n",
        "                    if predicted_classes[k] == False and classes[k] != i:\n",
        "                        true_negative[i] += 1\n",
        "\n",
        "    for i in range(len(f1score)):\n",
        "        recall[i] = true_positive[i] / target_positive[i]\n",
        "        precision[i] = true_positive[i] / predicted_positive[i]\n",
        "        f1score[i] = (2 * precision[i] * recall[i]) / (precision[i] + recall[i])\n",
        "        all_samp = target_positive[i] + predicted_positive[i] - true_positive[i] + true_negative[i]\n",
        "        perclass_acc[i] = (true_positive[i] + true_negative[i]) / all_samp\n",
        "\n",
        "    print('CLASS NAME\\t' + 'CLASS ACCURACY  \\t' + 'PRECISION\\t\\t' + 'RECALL   \\t\\t' + 'F1 SCORE\\t' + '\\t' + 'SAMPLES'.expandtabs(40))\n",
        "    for name in dictionary:\n",
        "        count = dictionary[name]\n",
        "        string = name + '\\t' + '%.4f'%perclass_acc[count] + '\\t' + '%.4f'%precision[count] + '\\t' + '%.4f'%recall[count] + '\\t' + '%.4f'%f1score[count] + '\\t' + str(target_positive[count])\n",
        "        print(string.expandtabs(22))\n",
        "\n",
        "    print('Average class accuracy: ' + '%.4f'%np.mean(perclass_acc))\n",
        "    print('Average precision: ' + '%.4f'%np.mean(precision))\n",
        "    print('Average recall: ' + '%.4f'%np.mean(recall))\n",
        "    print('Average F1 score: ' + '%.4f'%np.mean(f1score))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5WPUo_KSIgUL"
      },
      "source": [
        "print_metrics(model, test_loader, data_train.num_classes())\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eSEXsKW8JleE"
      },
      "source": [
        "print_metrics(model, train_loader, data_train.num_classes())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ty6oXwr2nopO"
      },
      "source": [
        "#REAL WORLD TESTING\n",
        "BASE_PATH = '/gdrive/My Drive/colab_files/'\n",
        "#UNCOMMENT TO UNTAR TEST PADDED SET\n",
        "'''\n",
        "if not os.path.exists('/gdrive/My Drive/colab_files/padded_test'):\n",
        "    os.makedirs('/gdrive/My Drive/colab_files/padded_test')\n",
        "print(os.getcwd())\n",
        "\n",
        "os.chdir(BASE_PATH)\n",
        "!ls\n",
        "!tar -zxf padded_test.tar.gz padded_test/test_combined \n",
        "print('Extracted test set')\n",
        "!tar -zxf padded_test.tar.gz padded_test/test_padded_data_ms_list.csv\n",
        "print('Extracted data lists')\n",
        "#!ls -1 | wc -l\n",
        "'''\n",
        "os.chdir(DATA_PATH)\n",
        "!ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HeEw5Sr5mg9S"
      },
      "source": [
        "os.chdir('/gdrive/My Drive/colab_files/padded_test')\n",
        "dictionary['None'] = 41\n",
        "data_test_padded = FreesoundDataset('test_padded_data_ms_list.csv', dictionary, 20, 'test_combined/') \n",
        "test_padded_loader = torch.utils.data.DataLoader(data_test_padded, batch_size=TEST_BATCH_SIZE,\n",
        "                                          shuffle=False, **kwargs)\n",
        "\n",
        "#LOADING BEST VGG MODEL\n",
        "DATA_PATH = '/gdrive/My Drive/colab_files/mel_spec_dataset_large/'\n",
        "os.chdir(DATA_PATH)\n",
        "LOG_PATH = DATA_PATH + 'logs/7.2/'\n",
        "model = get_vgg_model()\n",
        "\n",
        "start_epoch = load_last_model(model, LOG_PATH)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bBz01ArwrocY"
      },
      "source": [
        "def real_world(model, threshold, temperature):\n",
        "  correct = 0\n",
        "  with torch.no_grad():\n",
        "    for j, (inputs, classes) in enumerate(test_padded_loader):\n",
        "        inputs = inputs.to(device)\n",
        "        classes = classes.to(device)\n",
        "        outputs = model(inputs)\n",
        "        outputs = outputs/temperature\n",
        "        \n",
        "        all_predicted_probs = F.softmax(outputs, dim=1)\n",
        "        \n",
        "        predicted = torch.max(all_predicted_probs, 1)\n",
        "        pred_probs = predicted[0]\n",
        "        pred_classes = predicted[1]\n",
        "        for i in range(len(pred_probs)):\n",
        "            if pred_probs[i] < threshold:\n",
        "                pred_classes[i] = 41\n",
        "            if pred_classes[i] == classes[i]:\n",
        "                correct += 1\n",
        "\n",
        "  print('Threshold ' + str(threshold))\n",
        "  print('Accuracy ' + str (correct/len(data_test_padded)))\n",
        "\n",
        "for j in range(3, 10):\n",
        "  temp = 0.1*j  \n",
        "  print(temp)     \n",
        "  for i in range(2, 7):\n",
        "    t = 0.1 * i\n",
        "    real_world(model, t, temp)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PSl8A0bE0bCp"
      },
      "source": [
        "#LOADING BEST RESNET MODEL\n",
        "LOG_PATH = DATA_PATH + 'logs/7.13/'\n",
        "start_epoch = load_last_model(model, LOG_PATH)\n",
        "#UNCOMMENT REQUIRED SECTION FOR NONE CLASS \n",
        "#print_metrics(model, test_padded_loader, 42)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}